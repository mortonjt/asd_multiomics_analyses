{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70dccb5e",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Donor-recipient-matching\" data-toc-modified-id=\"Donor-recipient-matching-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Donor recipient matching</a></span></li><li><span><a href=\"#Age-sex-matching-table\" data-toc-modified-id=\"Age-sex-matching-table-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Age sex matching table</a></span></li><li><span><a href=\"#Before-and-after-perturbation\" data-toc-modified-id=\"Before-and-after-perturbation-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Before and after perturbation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Week-0-vs-Week-10\" data-toc-modified-id=\"Week-0-vs-Week-10-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Week 0 vs Week 10</a></span></li><li><span><a href=\"#Week-0-vs-Week-18\" data-toc-modified-id=\"Week-0-vs-Week-18-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Week 0 vs Week 18</a></span></li><li><span><a href=\"#Week-0-vs-week-100\" data-toc-modified-id=\"Week-0-vs-week-100-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Week 0 vs week 100</a></span></li></ul></li><li><span><a href=\"#Week-10-vs-Week-18\" data-toc-modified-id=\"Week-10-vs-Week-18-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Week 10 vs Week 18</a></span><ul class=\"toc-item\"><li><span><a href=\"#week-18-vs-week-100\" data-toc-modified-id=\"week-18-vs-week-100-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>week 18 vs week 100</a></span></li></ul></li><li><span><a href=\"#Below-is-scratch-work\" data-toc-modified-id=\"Below-is-scratch-work-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Below is scratch work</a></span></li><li><span><a href=\"#Standard-Kang-dataset-against-other-datasets\" data-toc-modified-id=\"Standard-Kang-dataset-against-other-datasets-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Standard Kang dataset against other datasets</a></span></li><li><span><a href=\"#Merge-Kang-et-al-with-combined-metadata-table\" data-toc-modified-id=\"Merge-Kang-et-al-with-combined-metadata-table-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Merge Kang et al with combined metadata table</a></span></li><li><span><a href=\"#Synchronize-biom-tables\" data-toc-modified-id=\"Synchronize-biom-tables-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Synchronize biom tables</a></span></li><li><span><a href=\"#Split-by-time\" data-toc-modified-id=\"Split-by-time-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Split by time</a></span></li><li><span><a href=\"#Split-by-donor\" data-toc-modified-id=\"Split-by-donor-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Split by donor</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2f3dea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from q2_matchmaker._matching import _matchmaker\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19517750",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def _standardize(x):\n",
    "    return (x - x.min()) / (x.max() - x.min())\n",
    "\n",
    "\n",
    "def _matchmaker(metadata, status, match_columns, types):\n",
    "    \"\"\" Computes matching ids.\n",
    "    Parameters\n",
    "    ----------\n",
    "    metadata : pd.DataFrame\n",
    "        Sample metadata\n",
    "    status : str\n",
    "        Column for specifying case-control status\n",
    "    match_columns : list of str\n",
    "        List of metadata categories\n",
    "    types : list of bool\n",
    "        Specifies if it is categorical or not.\n",
    "        True for categorical, False for continuous\n",
    "    Returns\n",
    "    -------\n",
    "    pd.Series : List of matching ids\n",
    "    \"\"\"\n",
    "    md = metadata.sort_values(by=status)\n",
    "    dummies = []\n",
    "    for col, cat in zip(match_columns, types):\n",
    "        if cat:\n",
    "            df = pd.get_dummies(md[col])\n",
    "            dummies.append(df)\n",
    "        else:\n",
    "            df = pd.DataFrame(_standardize(md[col]))\n",
    "            dummies.append(df)\n",
    "    dm = sum(map(lambda x: squareform(pdist(x)) ** 2, dummies))\n",
    "    i = (md[status].values == md[status].values[0]).sum()\n",
    "    x, y = linear_sum_assignment(dm[:i, i:])\n",
    "    y = y + i\n",
    "    md.loc[md.index[x], 'matching_id'] = x\n",
    "    md.loc[md.index[y], 'matching_id'] = x\n",
    "    return md['matching_id']\n",
    "\n",
    "def amplicon_to_ogu(table_, mapping):\n",
    "    t = table_.to_dataframe()\n",
    "    t = pd.merge(t, mapping['sequence'].reset_index(), left_index=True, right_on='sequence')\n",
    "    t = t.groupby('genome').sum()\n",
    "    t = biom.Table(t.values, list(t.index), list(t.columns))\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c877dc9",
   "metadata": {},
   "source": [
    "Load Kang et al metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bb1a0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "md = pd.read_table('Kang2017/sample_metadata.txt')\n",
    "md0 = pd.read_table('Kang2017/stool-metadata.txt')\n",
    "md1 = pd.read_excel('Kang2017/41598_2019_42183_MOESM2_ESM.xlsx', engine='openpyxl', skiprows=1)\n",
    "md2 = pd.read_excel('Kang2017/41598_2019_42183_MOESM3_ESM.xlsx', engine='openpyxl', skiprows=2)\n",
    "\n",
    "# some metadata massaging\n",
    "md['week'] = md['weeks-since-experiment-start']\n",
    "asd_donors = md0[['host_subject_id', 'bbt_donor_id']].drop_duplicates()\n",
    "md = pd.merge(md, asd_donors, left_on='host_subject_id', right_on='host_subject_id', how='outer')\n",
    "md = md.set_index('Run')\n",
    "# filter out non stool samples\n",
    "md = md.loc[md['collection-method'] == 'stool']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe1a0aa",
   "metadata": {},
   "source": [
    "Load 16S to WGS mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7523eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory paths\n",
    "amp_directory = 'Combined'\n",
    "wgs_directory = '../sra_shotgun/Combined'\n",
    "\n",
    "sam_file = f'{amp_directory}/age_sex_matched_seqs.sam'\n",
    "aligns = pd.read_table(sam_file, header=None)\n",
    "mapping = aligns[[0, 2]]\n",
    "mapping.columns = ['sequence', 'GOTU']\n",
    "taxonomy = pd.read_table('~/databases/wol/taxonomy/ranks.tsv', index_col=0)\n",
    "taxid = pd.read_table('~/databases/wol/taxonomy/taxid.map', header=None, dtype=str)\n",
    "taxid.columns = ['GOTU', 'genome']\n",
    "mapping = pd.merge(mapping, taxid, left_on='GOTU', right_on='GOTU')\n",
    "mapping = pd.merge(mapping, taxonomy, left_on='GOTU', right_index=True)\n",
    "mapping = mapping.set_index('genome')\n",
    "\n",
    "# load metagenome counts from all WGS datasets\n",
    "# and filter out all non-sensical mappings\n",
    "threshold = 100  # determined based on bimodality of count distribution\n",
    "gotu_totals = pd.read_csv(f'{wgs_directory}/feature_counts.csv', index_col=0)\n",
    "gotu_totals.index = list(map(str, gotu_totals.index))\n",
    "sane_otus = set(gotu_totals.loc[gotu_totals['0'] > threshold].index)\n",
    "mapping = mapping.loc[sane_otus & set(mapping.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c4c50f",
   "metadata": {},
   "source": [
    "# Donor recipient matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6458c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-7ff3e0b3b053>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  md_donor['donor_matching'] = md_donor['host_subject_id']\n",
      "<ipython-input-5-7ff3e0b3b053>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  md_host0['donor_matching'] = md_host0['bbt_donor_id']\n"
     ]
    }
   ],
   "source": [
    "import biom\n",
    "from biom.util import biom_open\n",
    "table = biom.load_table('Kang2017/deblur/all.biom')\n",
    "\n",
    "asd_donor_pairing = asd_donors.dropna().groupby('bbt_donor_id').first().reset_index()\n",
    "donor_idx = md['host_subject_id'].apply(lambda x: x in set(asd_donor_pairing['bbt_donor_id']))\n",
    "host_idx = md['host_subject_id'].apply(lambda x: x in set(asd_donor_pairing['host_subject_id']))\n",
    "md_donor = md.loc[donor_idx]\n",
    "md_host = md.loc[host_idx]\n",
    "md_host0 = md_host.loc[md_host['week'] == 0]\n",
    "md_donor['donor_matching'] = md_donor['host_subject_id']\n",
    "md_host0['donor_matching'] = md_host0['bbt_donor_id']\n",
    "md_donor = pd.concat((md_host0, md_donor), axis=0)\n",
    "\n",
    "# prepare donor biom table\n",
    "filter_f = lambda v, i, m: i in set(md_donor.index)\n",
    "table_ = table.filter(filter_f, axis='sample', inplace=False)\n",
    "filter_f = lambda v, i, m: np.sum(v) > 0\n",
    "table_.filter(filter_f, axis='observation')\n",
    "md_donor = md_donor[~md_donor.index.duplicated(keep='first')]\n",
    "with biom_open('Kang2017/donor.biom', 'w') as f:\n",
    "    table_.to_hdf5(f, 'kang_week0_donor')\n",
    "    \n",
    "md_donor.to_csv('Kang2017/donor_metadata.txt', sep='\\t')\n",
    "\n",
    "# Save separate OGU table\n",
    "t = amplicon_to_ogu(table_, mapping)\n",
    "with biom_open('Kang2017/donor_ogu.biom', 'w') as f:\n",
    "    t.to_hdf5(f, 'kang_week0_donor')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f260e034",
   "metadata": {},
   "source": [
    "# Age sex matching table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6fa6520",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-967f8259c311>:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  age_sex_md_0['Match_IDs'] = match_ids\n"
     ]
    }
   ],
   "source": [
    "md = pd.read_table('Kang2017/sample_metadata.txt')\n",
    "md2 = pd.read_excel('Kang2017/41598_2019_42183_MOESM3_ESM.xlsx', engine='openpyxl', skiprows=2)\n",
    "\n",
    "# obtain age/sex information for the controls\n",
    "md2 = md2[['Code', 'age', 'gender']]\n",
    "def g(x):\n",
    "    if x == 'M':\n",
    "        return 'male'\n",
    "    else:\n",
    "        return 'female'\n",
    "md2['Sex'] = md2.gender.apply(g)\n",
    "md2['Age'] = md2['age']\n",
    "md2 = md2.set_index('Code')[['Age', 'Sex']]\n",
    "md = pd.merge(md, md2, left_on='host_subject_id', right_on='Code')\n",
    "md['Sex'] = md['Sex_y']\n",
    "md['Age'] = md['Age_y']\n",
    "md['week'] = md['weeks-since-experiment-start']\n",
    "# age sex matching\n",
    "age_sex_md = md.dropna(subset=['Age', 'Sex', 'Status'])\n",
    "age_sex_md_0 = age_sex_md.loc[age_sex_md['week'] == 0]\n",
    "match_ids = _matchmaker(age_sex_md_0, 'Status', ['Age', 'Sex'], [False, True])\n",
    "match_ids = match_ids.dropna().astype(np.int64).apply(lambda x: f'Kang_{x}')\n",
    "age_sex_md_0['Match_IDs'] = match_ids\n",
    "age_sex_md_0 = age_sex_md_0.dropna(subset=['Match_IDs'])\n",
    "age_sex_md_0 = age_sex_md_0.set_index('Run')\n",
    "# merge metadata\n",
    "combined_md = pd.read_table('Combined/age_sex_match_metadata.txt', index_col=0)\n",
    "combined_md0 = pd.concat((age_sex_md_0[combined_md.columns], combined_md), axis=0)\n",
    "# match biom tables\n",
    "table = biom.load_table('Combined/age_sex_matched.biom')\n",
    "kang = biom.load_table('Kang2017/deblur/all.biom')\n",
    "filter_0 = lambda v, i, m: i in combined_md0.index\n",
    "kang_0 = kang.filter(filter_0, inplace=False)\n",
    "# filter out low abundance microbes\n",
    "filter_obs = lambda v, i, m: np.sum(v > 0) > 3\n",
    "kang_0.filter(filter_obs, axis='observation')\n",
    "combined_0 = table.merge(kang_0)\n",
    "# save biom table and metadata\n",
    "combined_md0.to_csv('Kang2017/combined_sample_metadata_0.txt', sep='\\t')\n",
    "with biom_open('Kang2017/age_sex_match_week0.biom', 'w') as f:\n",
    "    combined_0.to_hdf5(f, 'combined_kang_week0')\n",
    "    \n",
    "# save biom table with ogu ids\n",
    "t = amplicon_to_ogu(combined_0, mapping)\n",
    "with biom_open('Kang2017/age_sex_match_week0_ogu.biom', 'w') as f:\n",
    "    t.to_hdf5(f, 'combined_kang_week0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bba40b2",
   "metadata": {},
   "source": [
    "# Before and after perturbation\n",
    "\n",
    "## Week 0 vs Week 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1153e581",
   "metadata": {},
   "outputs": [],
   "source": [
    "end = 10\n",
    "md = pd.read_table('Kang2017/sample_metadata.txt')\n",
    "md = md.set_index('Run')\n",
    "asd_md = md.loc[md.Status == 'ASD']\n",
    "asd_md = asd_md[asd_md['collection-method'] == 'stool']\n",
    "asd_md['week'] = asd_md['weeks-since-experiment-start'] \n",
    "week0 = asd_md['weeks-since-experiment-start'] == 0\n",
    "weeklr = asd_md['weeks-since-experiment-start'] == end\n",
    "asd_md = asd_md.loc[np.logical_or(week0, weeklr)]\n",
    "asd_md = asd_md.groupby('host_subject_id').filter(lambda x: len(x) == 2)\n",
    "filter_asd = lambda v, i, m: i in set(asd_md.index)\n",
    "kang_asd = kang.filter(filter_asd, inplace=False)\n",
    "filter_obs = lambda v, i, m: np.sum(v > 0) > 0\n",
    "#kang_asd.filter(filter_obs, axis='observation')\n",
    "with biom_open(f'Kang2017/week0_week{end}.biom', 'w') as f:\n",
    "    kang_asd.to_hdf5(f, f'kang_week0_{end}')\n",
    "# save OGU table\n",
    "t = amplicon_to_ogu(kang_asd, mapping)\n",
    "with biom_open(f'Kang2017/week0_week{end}_ogu.biom', 'w') as f:\n",
    "    t.to_hdf5(f, f'kang_week0_{end}')\n",
    "    \n",
    "asd_md['week'] = asd_md['week'].astype(np.int64)\n",
    "asd_md['week_time'] = asd_md['week'].apply(lambda x: f'A{x}')\n",
    "asd_md.loc[kang_asd.ids()].to_csv(f'Kang2017/asd_metadata_w{end}.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7504380c",
   "metadata": {},
   "source": [
    "## Week 0 vs Week 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1831bc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "end = 18\n",
    "md = pd.read_table('Kang2017/sample_metadata.txt')\n",
    "md = md.set_index('Run')\n",
    "asd_md = md.loc[md.Status == 'ASD']\n",
    "asd_md = asd_md[asd_md['collection-method'] == 'stool']\n",
    "asd_md['week'] = asd_md['weeks-since-experiment-start'] \n",
    "week0 = asd_md['weeks-since-experiment-start'] == 0\n",
    "weeklr = asd_md['weeks-since-experiment-start'] == end\n",
    "asd_md = asd_md.loc[np.logical_or(week0, weeklr)]\n",
    "asd_md = asd_md.groupby('host_subject_id').filter(lambda x: len(x) == 2)\n",
    "filter_asd = lambda v, i, m: i in set(asd_md.index)\n",
    "kang_asd = kang.filter(filter_asd, inplace=False)\n",
    "filter_obs = lambda v, i, m: np.sum(v > 0) > 0\n",
    "#kang_asd.filter(filter_obs, axis='observation')\n",
    "with biom_open(f'Kang2017/week0_week{end}.biom', 'w') as f:\n",
    "    kang_asd.to_hdf5(f, f'kang_week0_{end}')\n",
    "# save OGU table\n",
    "t = amplicon_to_ogu(kang_asd, mapping)\n",
    "with biom_open(f'Kang2017/week0_week{end}_ogu.biom', 'w') as f:\n",
    "    t.to_hdf5(f, f'kang_week0_{end}')\n",
    "    \n",
    "asd_md['week'] = asd_md['week'].astype(np.int64)\n",
    "asd_md['week_time'] = asd_md['week'].apply(lambda x: f'A{x}')\n",
    "asd_md.loc[kang_asd.ids()].to_csv(f'Kang2017/asd_metadata_w{end}.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81864962",
   "metadata": {},
   "source": [
    "## Week 0 vs week 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d167b319",
   "metadata": {},
   "outputs": [],
   "source": [
    "end = 100\n",
    "md = pd.read_table('Kang2017/sample_metadata.txt')\n",
    "md = md.set_index('Run')\n",
    "asd_md = md.loc[md.Status == 'ASD']\n",
    "asd_md = asd_md[asd_md['collection-method'] == 'stool']\n",
    "asd_md['week'] = asd_md['weeks-since-experiment-start'] \n",
    "week0 = asd_md['weeks-since-experiment-start'] == 0\n",
    "weeklr = asd_md['weeks-since-experiment-start'] == end\n",
    "asd_md = asd_md.loc[np.logical_or(week0, weeklr)]\n",
    "asd_md = asd_md.groupby('host_subject_id').filter(lambda x: len(x) == 2)\n",
    "filter_asd = lambda v, i, m: i in set(asd_md.index)\n",
    "kang_asd = kang.filter(filter_asd, inplace=False)\n",
    "filter_obs = lambda v, i, m: np.sum(v > 0) > 0\n",
    "#kang_asd.filter(filter_obs, axis='observation')\n",
    "with biom_open(f'Kang2017/week0_week{end}.biom', 'w') as f:\n",
    "    kang_asd.to_hdf5(f, f'kang_week0_{end}')\n",
    "# save OGU table\n",
    "t = amplicon_to_ogu(kang_asd, mapping)\n",
    "with biom_open(f'Kang2017/week0_week{end}_ogu.biom', 'w') as f:\n",
    "    t.to_hdf5(f, f'kang_week0_{end}')\n",
    "    \n",
    "asd_md['week'] = asd_md['week'].astype(np.int64)\n",
    "asd_md['week_time'] = asd_md['week'].apply(lambda x: f'A{x}')\n",
    "asd_md.loc[kang_asd.ids()].to_csv(f'Kang2017/asd_metadata_w{end}.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9f9ed4",
   "metadata": {},
   "source": [
    "# Week 10 vs Week 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0c74e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 10\n",
    "end = 100\n",
    "md = pd.read_table('Kang2017/sample_metadata.txt')\n",
    "md = md.set_index('Run')\n",
    "asd_md = md.loc[md.Status == 'ASD']\n",
    "asd_md = asd_md[asd_md['collection-method'] == 'stool']\n",
    "asd_md['week'] = asd_md['weeks-since-experiment-start'] \n",
    "week0 = asd_md['weeks-since-experiment-start'] == start\n",
    "weeklr = asd_md['weeks-since-experiment-start'] == end\n",
    "asd_md = asd_md.loc[np.logical_or(week0, weeklr)]\n",
    "asd_md = asd_md.groupby('host_subject_id').filter(lambda x: len(x) == 2)\n",
    "filter_asd = lambda v, i, m: i in set(asd_md.index)\n",
    "kang_asd = kang.filter(filter_asd, inplace=False)\n",
    "filter_obs = lambda v, i, m: np.sum(v > 0) > 0\n",
    "#kang_asd.filter(filter_obs, axis='observation')\n",
    "with biom_open(f'Kang2017/week{start}_week{end}.biom', 'w') as f:\n",
    "    kang_asd.to_hdf5(f, f'kang_week{start}_{end}')\n",
    "# save OGU table\n",
    "t = amplicon_to_ogu(kang_asd, mapping)\n",
    "with biom_open(f'Kang2017/week0_week{end}_ogu.biom', 'w') as f:\n",
    "    t.to_hdf5(f, f'kang_week0_{end}')\n",
    "    \n",
    "asd_md['week'] = asd_md['week'].astype(np.int64)\n",
    "asd_md['week_time'] = asd_md['week'].apply(lambda x: f'A{x}')\n",
    "asd_md.loc[kang_asd.ids()].to_csv(f'Kang2017/asd_metadata_w_{start}w{end}.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bcd12a",
   "metadata": {},
   "source": [
    "## week 18 vs week 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8219067b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 18\n",
    "end = 100\n",
    "md = pd.read_table('Kang2017/sample_metadata.txt')\n",
    "md = md.set_index('Run')\n",
    "asd_md = md.loc[md.Status == 'ASD']\n",
    "asd_md = asd_md[asd_md['collection-method'] == 'stool']\n",
    "asd_md['week'] = asd_md['weeks-since-experiment-start'] \n",
    "week0 = asd_md['weeks-since-experiment-start'] == start\n",
    "weeklr = asd_md['weeks-since-experiment-start'] == end\n",
    "asd_md = asd_md.loc[np.logical_or(week0, weeklr)]\n",
    "asd_md = asd_md.groupby('host_subject_id').filter(lambda x: len(x) == 2)\n",
    "filter_asd = lambda v, i, m: i in set(asd_md.index)\n",
    "kang_asd = kang.filter(filter_asd, inplace=False)\n",
    "filter_obs = lambda v, i, m: np.sum(v > 0) > 0\n",
    "#kang_asd.filter(filter_obs, axis='observation')\n",
    "with biom_open(f'Kang2017/week{start}_week{end}.biom', 'w') as f:\n",
    "    kang_asd.to_hdf5(f, f'kang_week{start}_{end}')\n",
    "# save OGU table\n",
    "t = amplicon_to_ogu(kang_asd, mapping)\n",
    "with biom_open(f'Kang2017/week{start}_week{end}_ogu.biom', 'w') as f:\n",
    "    t.to_hdf5(f, f'kang_week{start}_{end}')\n",
    "    \n",
    "asd_md['week'] = asd_md['week'].astype(np.int64)\n",
    "asd_md['week_time'] = asd_md['week'].apply(lambda x: f'A{x}')\n",
    "asd_md.loc[kang_asd.ids()].to_csv(f'Kang2017/asd_metadata_w_{start}w{end}.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31962420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weeks-since-experiment-start</th>\n",
       "      <th>Age</th>\n",
       "      <th>cars</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GROUP</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>autism</th>\n",
       "      <td>13.692015</td>\n",
       "      <td>11.086312</td>\n",
       "      <td>35.924242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>donor-initial</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>donor-maintenance</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neurotypical</th>\n",
       "      <td>8.223464</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neurotypical_mom</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   weeks-since-experiment-start        Age       cars\n",
       "GROUP                                                                \n",
       "autism                                13.692015  11.086312  35.924242\n",
       "donor-initial                               NaN        NaN        NaN\n",
       "donor-maintenance                           NaN        NaN        NaN\n",
       "neurotypical                           8.223464        NaN        NaN\n",
       "neurotypical_mom                       0.000000        NaN        NaN"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md.groupby('GROUP').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fb6731",
   "metadata": {},
   "source": [
    "# Below is scratch work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed914251",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "['week']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e97788882dee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'week'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m18\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'week'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmd_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'week'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Age'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Sex'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/catvae/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdropna\u001b[0;34m(self, axis, how, thresh, subset, inplace)\u001b[0m\n\u001b[1;32m   5160\u001b[0m             \u001b[0mcheck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5161\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5162\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5163\u001b[0m             \u001b[0magg_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ['week']"
     ]
    }
   ],
   "source": [
    "def filter_f(x):\n",
    "    return (0 not in x['week']) and (18 not in x['week'])\n",
    "\n",
    "md_ = md.dropna(subset=['week', 'Age', 'Sex'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3a4095",
   "metadata": {},
   "source": [
    "# Standard Kang dataset against other datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391015ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_f(x):\n",
    "    return (0 not in x['week']) and (18 not in x['week'])\n",
    "# select only week 0 and filter out subjects that didn't collect at least 2 time points\n",
    "md0['week'] = md0['week'].astype(np.int64)\n",
    "md0 = md0.groupby(['host_subject_id']).filter(lambda x: len(x) >= 2)\n",
    "# merge metadata\n",
    "md = pd.merge(md0, md2[['Code', 'age', 'gender']], left_on='host_subject_id', right_on='Code')\n",
    "md = md.set_index('sampleid')\n",
    "md = md[['gender', 'age', 'week', 'host_subject_id', 'experimental_group']]\n",
    "\n",
    "# perform matching\n",
    "md_week0 = md.loc[md.week == 0.0]\n",
    "match_ids = _matchmaker(md_week0, 'experimental_group', ['age', 'gender'], [False, True])\n",
    "match_ids = match_ids.dropna().astype(np.int64).apply(lambda x: f'Kang_{x}')\n",
    "md_week0['match_ids'] = match_ids\n",
    "\n",
    "md = pd.merge(md.reset_index(), md_week0[['host_subject_id', 'match_ids']], \n",
    "              left_on='host_subject_id', right_on='host_subject_id')\n",
    "\n",
    "md = md.dropna()\n",
    "\n",
    "md = md.rename(columns={\n",
    "    'gender': 'Sex', 'age': 'Age',\n",
    "    'experimental_group': 'Status'\n",
    "})\n",
    "# sync\n",
    "def f(x):\n",
    "    if x == 'autism':\n",
    "        return 'ASD'\n",
    "    else:\n",
    "        return 'Control'\n",
    "    \n",
    "\n",
    "md['Status'] = md.Status.apply(f)\n",
    "\n",
    "md = md.set_index('sampleid')\n",
    "\n",
    "\n",
    "md['Sex'] = md.Sex.apply(g)\n",
    "\n",
    "# drop all samples that weren't collected at 0 or 18\n",
    "idx = np.logical_or(md.week == 0.0, md.week == 18.0)\n",
    "sub_md = md.loc[idx]\n",
    "sub_md['Match_IDs'] = sub_md.apply(lambda x: x['match_ids'] + '_' + str(int(x['week'])), axis=1)\n",
    "# add other information\n",
    "sub_md['Cohort'] = 'Kang2017'\n",
    "sub_md['Control_Type'] = 'Intervention'\n",
    "sub_md['Subjects_Location'] = 'USA'\n",
    "sub_md['Variable_Region'] = 'V4'\n",
    "sub_md.to_csv('Kang2017/sample_metadata_matched.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290486aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "md0.loc[md0['experimental_group'] == 'neurotypical']['week'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2426741d",
   "metadata": {},
   "source": [
    "# Merge Kang et al with combined metadata table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6822f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_md = pd.read_table('Combined/age_sex_match_metadata.txt', index_col=0)\n",
    "combined_md0 = pd.concat((sub_md.loc[sub_md.week == 0, combined_md.columns], combined_md), axis=0)\n",
    "combined_md18 = pd.concat((sub_md.loc[sub_md.week == 18, combined_md.columns], combined_md), axis=0)\n",
    "combined_md0.to_csv('Kang2017/combined_sample_metadata_0.txt', sep='\\t')\n",
    "combined_md18.to_csv('Kang2017/combined_sample_metadata_18.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86d38fb",
   "metadata": {},
   "source": [
    "# Synchronize biom tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f081b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import biom\n",
    "\n",
    "table = biom.load_table('Combined/age_sex_matched.biom')\n",
    "kang = biom.load_table('Kang2017/deblur/qiita.biom')\n",
    "\n",
    "filter_0 = lambda v, i, m: i in combined_md0.index\n",
    "kang_0 = kang.filter(filter_0, inplace=False)\n",
    "\n",
    "filter_18 = lambda v, i, m: i in combined_md18.index\n",
    "kang_18 = kang.filter(filter_18, inplace=False)\n",
    "\n",
    "# filter out low abundance microbes\n",
    "filter_obs = lambda v, i, m: np.sum(v > 0) > 3\n",
    "kang_0.filter(filter_obs, axis='observation')\n",
    "kang_18.filter(filter_obs, axis='observation')\n",
    "\n",
    "combined_0 = table.merge(kang_0)\n",
    "combined_18 = table.merge(kang_18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c03f852",
   "metadata": {},
   "outputs": [],
   "source": [
    "from biom.util import biom_open\n",
    "\n",
    "with biom_open('Kang2017/age_sex_match_week0.biom', 'w') as f:\n",
    "    combined_0.to_hdf5(f, 'combined_kang_week0')\n",
    "    \n",
    "with biom_open('Kang2017/age_sex_match_week18.biom', 'w') as f:\n",
    "    combined_18.to_hdf5(f, 'combined_kang_week18')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c339e860",
   "metadata": {},
   "source": [
    "# Split by time\n",
    "\n",
    "We need to compute diff abundance wrt time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81ce52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "asd_md = sub_md.loc[sub_md.Status == 'ASD']\n",
    "\n",
    "filter_asd = lambda v, i, m: i in asd_md.index\n",
    "kang_asd = kang.filter(filter_asd, inplace=False)\n",
    "\n",
    "filter_obs = lambda v, i, m: np.sum(v > 0) > 3\n",
    "kang_asd.filter(filter_obs, axis='observation')\n",
    "\n",
    "with biom_open('Kang2017/week0_week18.biom', 'w') as f:\n",
    "    kang_asd.to_hdf5(f, 'kang_week0_18')\n",
    "    \n",
    "asd_md.to_csv('Kang2017/asd_metadata.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e779bcb4",
   "metadata": {},
   "source": [
    "# Split by donor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5d69e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "md = pd.read_table('Kang2017/sample_metadata.txt')\n",
    "md = md.set_index('Run')\n",
    "\n",
    "table = biom.load_table('Kang2017/deblur/all.biom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e772bf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88db2d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f966dcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b645238",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_md = pd.merge(md0, md2[['Code', 'age', 'gender']], left_on='host_subject_id', right_on='Code')\n",
    "full_md = full_md.set_index('sampleid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20a79a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_md.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34816867",
   "metadata": {},
   "outputs": [],
   "source": [
    "md0['mom_kid'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d361560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_md.host_subject_id.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970fdd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_md.bbt_donor_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa595f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_md.maintenance_bbt_donor_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e673e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "md2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946e64c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
